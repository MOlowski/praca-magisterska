{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "NkcudwaaMVUz",
        "MbFl_6Kx8uAT",
        "3H4NKCEsUV_h",
        "mdd17LahTzCN",
        "YvZ0XbZ5T2p0",
        "ilOAIuTCU7fG",
        "aRzubI8XU-vy",
        "vZEVUJlK8EQi",
        "i0G_XNHf8HrE"
      ],
      "mount_file_id": "1xU9oJKso_tUikSOiTIIJmcgqZJhk5uZC",
      "authorship_tag": "ABX9TyPzYuioZ47xKHrGfz4RZKkY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MOlowski/praca-magisterska/blob/main/Pybullet_Ant_A2C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing and importing packages"
      ],
      "metadata": {
        "id": "upyh68qj6apg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ixbl-3RDQXh6"
      },
      "outputs": [],
      "source": [
        "!pip install pybullet\n",
        "!pip install stable_baselines3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rkuo2000/pybullet-gym\n",
        "%cd pybullet-gym"
      ],
      "metadata": {
        "id": "gFolcYVxTk-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "from stable_baselines3 import A2C, PPO, SAC, TD3\n",
        "import os\n",
        "import pybullet\n",
        "import pybulletgym.envs"
      ],
      "metadata": {
        "id": "X63H6ph5Qlyw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Ant model with A2C algorithm and saving it"
      ],
      "metadata": {
        "id": "16caJW9_61M9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models_dir = 'models/A2C'\n",
        "logdir = '../drive/MyDrive/Colab_Notebooks/logs'\n",
        "\n",
        "if not os.path.exists(models_dir):\n",
        "  os.makedirs(models_dir)\n",
        "\n",
        "if not os.path.exists(logdir):\n",
        "  os.makedirs(logdir)\n",
        "\n",
        "env_name = 'Ant'\n",
        "env = gym.make(env_name+'PyBulletEnv-v0')\n",
        "\n",
        "env.reset()"
      ],
      "metadata": {
        "id": "LWoLwI_kQ-Bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### test"
      ],
      "metadata": {
        "id": "NkcudwaaMVUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = A2C('MlpPolicy', env, verbose = 1, tensorboard_log= logdir)\n",
        "\n",
        "TIMESTEPS = 10000\n",
        "iters = 0\n",
        "for i in range(100):\n",
        "  model.learn(total_timesteps = TIMESTEPS, reset_num_timesteps = False, tb_log_name= 'A2C_test_log')\n",
        "  model.save(f'{models_dir}/{TIMESTEPS*i}')"
      ],
      "metadata": {
        "id": "tGwnc0GUMWYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "y2qSWfiUOOY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## training with different timesteps"
      ],
      "metadata": {
        "id": "MbFl_6Kx8uAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = A2C('MlpPolicy', env, verbose = 1, tensorboard_log= logdir)\n",
        "\n",
        "TIMESTEPS = 10000\n",
        "iters = 0\n",
        "for i in range(100):\n",
        "  model.learn(total_timesteps = TIMESTEPS, reset_num_timesteps = False, tb_log_name= 'A2C_1_m_ts')\n",
        "  model.save(f'{models_dir}/{TIMESTEPS*i}')"
      ],
      "metadata": {
        "id": "_prtcuRdThtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = A2C('MlpPolicy', env, verbose = 1, tensorboard_log= logdir)\n",
        "\n",
        "TIMESTEPS = 20000\n",
        "iters = 0\n",
        "for i in range(100):\n",
        "  model.learn(total_timesteps = TIMESTEPS, reset_num_timesteps = False, tb_log_name= 'A2C_2_m_ts')\n",
        "  model.save(f'{models_dir}/{TIMESTEPS*i}')"
      ],
      "metadata": {
        "id": "Mrz3BVMy7w9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = A2C('MlpPolicy', env, verbose = 1, tensorboard_log= logdir)\n",
        "\n",
        "TIMESTEPS = 30000\n",
        "iters = 0\n",
        "for i in range(100):\n",
        "  model.learn(total_timesteps = TIMESTEPS, reset_num_timesteps = False, tb_log_name= 'A2C_3_m_ts')\n",
        "  model.save(f'{models_dir}/{TIMESTEPS*i}')"
      ],
      "metadata": {
        "id": "SDCpn0SM75U7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning rates models"
      ],
      "metadata": {
        "id": "Ch3NIVMtTs3x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### lr = 0.002"
      ],
      "metadata": {
        "id": "3H4NKCEsUV_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# learning rates model\n",
        "\n",
        "# 0,002\n",
        "\n",
        "model_lr_2 = A2C('MlpPolicy', env, learning_rate = 0.002, verbose = 1, tensorboard_log= logdir)\n",
        "\n",
        "TIMESTEPS = 10000\n",
        "iters = 0\n",
        "for i in range(100):\n",
        "  model_lr_2.learn(total_timesteps = TIMESTEPS, reset_num_timesteps = False, tb_log_name= 'A2C_lr_2')\n",
        "  model_lr_2.save(f'{models_dir}/{TIMESTEPS*i}')"
      ],
      "metadata": {
        "id": "5vUtZssUR9EO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### lr = 0.003"
      ],
      "metadata": {
        "id": "mdd17LahTzCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_lr_3 = A2C('MlpPolicy', env, learning_rate = 0.003, verbose = 1, tensorboard_log= logdir)\n",
        "\n",
        "TIMESTEPS = 10000\n",
        "iters = 0\n",
        "for i in range(100):\n",
        "  model_lr_3.learn(total_timesteps = TIMESTEPS, reset_num_timesteps = False, tb_log_name= 'A2C_lr_3')\n",
        "  model_lr_3.save(f'{models_dir}/{TIMESTEPS*i}')"
      ],
      "metadata": {
        "id": "5PLgmnKsT2Uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### lr = 0.004"
      ],
      "metadata": {
        "id": "YvZ0XbZ5T2p0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_lr_4 = A2C('MlpPolicy', env, learning_rate = 0.004, verbose = 1, tensorboard_log= logdir)\n",
        "\n",
        "TIMESTEPS = 10000\n",
        "iters = 0\n",
        "for i in range(100):\n",
        "  model_lr_4.learn(total_timesteps = TIMESTEPS, reset_num_timesteps = False, tb_log_name= 'A2C_lr_4')\n",
        "  model_lr_4.save(f'{models_dir}/{TIMESTEPS*i}')"
      ],
      "metadata": {
        "id": "iJLrC-ikT8fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entropy beta models"
      ],
      "metadata": {
        "id": "5SvlGSb5T7mf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ent_coef = 0.02"
      ],
      "metadata": {
        "id": "ilOAIuTCU7fG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# entropy beta\n",
        "\n",
        "model_ec_2 = A2C('MlpPolicy', env, ent_coef = 0.02, verbose = 1, tensorboard_log= logdir)\n",
        "\n",
        "TIMESTEPS = 10000\n",
        "iters = 0\n",
        "for i in range(100):\n",
        "  model_ec_2.learn(total_timesteps = TIMESTEPS, reset_num_timesteps = False, tb_log_name= 'A2C_ec_2')\n",
        "  model_ec_2.save(f'{models_dir}/{TIMESTEPS*i}')"
      ],
      "metadata": {
        "id": "2WPHTPmwU-ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ent_coef = 0.03"
      ],
      "metadata": {
        "id": "aRzubI8XU-vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# entropy beta\n",
        "\n",
        "model_ec_3 = A2C('MlpPolicy', env, ent_coef = 0.03, verbose = 1, tensorboard_log= logdir)\n",
        "\n",
        "TIMESTEPS = 10000\n",
        "iters = 0\n",
        "for i in range(100):\n",
        "  model_ec_3.learn(total_timesteps = TIMESTEPS, reset_num_timesteps = False, tb_log_name= 'A2C_ec_3')\n",
        "  model_ec_3.save(f'{models_dir}/{TIMESTEPS*i}')"
      ],
      "metadata": {
        "id": "rzLK0b9PVAJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## count of environments"
      ],
      "metadata": {
        "id": "CLxcr0rRWltY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.env_util import make_vec_env"
      ],
      "metadata": {
        "id": "MAYXVikvi8pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5 envs"
      ],
      "metadata": {
        "id": "vZEVUJlK8EQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# count of envinorments\n",
        "\n",
        "# 5\n",
        "\n",
        "env_name = 'Ant'\n",
        "env_n_5 = make_vec_env(env_name+'PyBulletEnv-v0', n_envs = 5)\n",
        "\n",
        "env_n_5.reset()\n",
        "\n",
        "model_n_envs_5 = A2C('MlpPolicy', env, verbose = 1, tensorboard_log= logdir)\n",
        "\n",
        "TIMESTEPS = 10000\n",
        "iters = 0\n",
        "for i in range(100):\n",
        "  model_n_envs_5.learn(total_timesteps = TIMESTEPS, reset_num_timesteps = False, tb_log_name= 'A2C_n_envs_5')\n",
        "  model_n_envs_5.save(f'{models_dir}/{TIMESTEPS*i}')"
      ],
      "metadata": {
        "id": "wobIdY1MSFBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10 envs"
      ],
      "metadata": {
        "id": "i0G_XNHf8HrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# count of envinorments\n",
        "\n",
        "# 10\n",
        "\n",
        "env_name = 'Ant'\n",
        "env_n_10 = make_vec_env(env_name+'PyBulletEnv-v0', n_envs = 10)\n",
        "\n",
        "env_n_10.reset()\n",
        "\n",
        "model_n_envs_10 = A2C('MlpPolicy', env, verbose = 1, tensorboard_log= logdir)\n",
        "\n",
        "TIMESTEPS = 10000\n",
        "iters = 0\n",
        "for i in range(100):\n",
        "  model_n_envs_10.learn(total_timesteps = TIMESTEPS, reset_num_timesteps = False, tb_log_name= 'A2C_n_envs_10')\n",
        "  model_n_envs_10.save(f'{models_dir}/{TIMESTEPS*i}')\n"
      ],
      "metadata": {
        "id": "5V1aNSQ1YdBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 30 envs"
      ],
      "metadata": {
        "id": "7ImSjxqT8GOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# count of envinorments\n",
        "\n",
        "# 30\n",
        "\n",
        "env_name = 'Ant'\n",
        "env_n_30 = make_vec_env(env_name+'PyBulletEnv-v0', n_envs = 30)\n",
        "\n",
        "env_n_30.reset()\n",
        "\n",
        "model_n_envs_30 = A2C('MlpPolicy', env, verbose = 1, tensorboard_log= logdir)\n",
        "\n",
        "TIMESTEPS = 10000\n",
        "iters = 0\n",
        "for i in range(100):\n",
        "  model_n_envs_30.learn(total_timesteps = TIMESTEPS, reset_num_timesteps = False, tb_log_name= 'A2C_n_envs_30')\n",
        "  model_n_envs_30.save(f'{models_dir}/{TIMESTEPS*i}')\n"
      ],
      "metadata": {
        "id": "d2jmvuFRSJg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TensorBoard - results"
      ],
      "metadata": {
        "id": "ugx25SeJWxiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir='../drive/MyDrive/Colab_Notebooks/logs'\n"
      ],
      "metadata": {
        "id": "HJF10xg-pqT6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}